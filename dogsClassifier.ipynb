{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.image as img\n",
    "import PIL.Image\n",
    "import glob\n",
    "import random\n",
    "import base64\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thumbnail(path): \n",
    "    image = img.imread(path)\n",
    "    return image\n",
    "\n",
    "def image_base64(im):\n",
    "    if isinstance(im, str):\n",
    "        im = get_thumbnail(im)\n",
    "    with BytesIO() as buffer:\n",
    "        im.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def image_formatter(im):\n",
    "    return f'<img src=\"data:image/jpeg;base64,{image_base64(im)}\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = pd.read_csv('../dog-breed-identification/labels.csv')\n",
    "#dogs = dogs.sample(50)\n",
    "dogs['file'] = dogs.id.map(lambda id: f'/home/diegotakei/workspace/dog/dog-breed-identification/train/{id}.jpg')\n",
    "dogs['image'] = dogs.file.map(lambda f: get_thumbnail(f))\n",
    "dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = pd.read_csv('../dogs_data/labels.csv')\n",
    "dogs = dogs[:5000]\n",
    "dogs['file'] = dogs.id.map(lambda id: f'../dogs_data/resized/{id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = []\n",
    "for f in dogs['file'].values:\n",
    "    imgs.append(get_thumbnail(f))\n",
    "imgs = np.array(imgs)\n",
    "\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_row_to_float = lambda row: list(map(lambda element: float(element), row))\n",
    "int_matrix_to_float = lambda matrix: list(map(lambda row: int_row_to_float(row), matrix))\n",
    "img_to_float = lambda img: list(map(lambda dimension: int_matrix_to_float(dimension), img))\n",
    "\n",
    "float_imgs = list(map(lambda img: img_to_float(img), imgs[:5]))\n",
    "float_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 256, 256, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_imgs = imgs.astype(float)\n",
    "float_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['Indexes'] = dogs[\"breed\"].str.startswith('appenzeller')\n",
    "    \n",
    "result = dogs[(dogs.Indexes == True)]\n",
    "result.tail()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "HTML(result[['breed', 'image']].to_html(formatters={'image': image_formatter}, escape=False))\n",
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = float_imgs\n",
    "\n",
    "train_labels = dogs['breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boston_bull'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(features, labels, mode):\n",
    "\n",
    "    i = tf.reshape(features['x'], [-1, 256, 256, 3])\n",
    "    \n",
    "    # receives [batch_size, 256, 256, 3]\n",
    "    # returns [batch_size, 256, 256, 32]\n",
    "    convolution1 = tf.layers.conv2d(inputs = i, filters = 32, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                 padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 256, 256, 32]\n",
    "    # returns [batch_size, 128, 128, 32]\n",
    "    pooling1 = tf.layers.max_pooling2d(inputs = convolution1, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 128, 128, 32]\n",
    "    # returns [batch_size, 128, 128, 64]\n",
    "    convolution2 = tf.layers.conv2d(inputs = pooling1, filters = 64, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                  padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 128, 128, 64]\n",
    "    # returns [batch_size, 64, 64, 64]\n",
    "    pooling2 = tf.layers.max_pooling2d(inputs = convolution2, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 64, 64, 64]\n",
    "    # returns [batch_size, 64, 64, 128]\n",
    "    convolution3 = tf.layers.conv2d(inputs = pooling2, filters = 32, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                 padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 64, 64, 128]\n",
    "    # returns [batch_size, 32, 32, 128]\n",
    "    pooling3 = tf.layers.max_pooling2d(inputs = convolution3, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 32, 32, 128]\n",
    "    # returns [batch_size, 32, 32, 256]\n",
    "    convolution4 = tf.layers.conv2d(inputs = pooling3, filters = 32, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                 padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 32, 32, 256]\n",
    "    # returns [batch_size, 16, 16, 256]\n",
    "    pooling4 = tf.layers.max_pooling2d(inputs = convolution4, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 16, 16, 256]\n",
    "    # returns [batch_size, 16, 16, 512]\n",
    "    convolution5 = tf.layers.conv2d(inputs = pooling4, filters = 32, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                 padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 16, 16, 512]\n",
    "    # returns [batch_size, 8, 8, 512]\n",
    "    pooling5 = tf.layers.max_pooling2d(inputs = convolution5, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 8, 8, 512]\n",
    "    # returns [batch_size, 8*8*512]\n",
    "    flattening = tf.reshape(pooling3, [-1, 8 * 8 * 512])\n",
    "    \n",
    "    # 3136 inputs -> 1024 neurons on hidden layer -> 10 outputs\n",
    "    # receives [batch_size, 3136]\n",
    "    # returns [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs = flattening, units = 1024, activation = tf.nn.relu)\n",
    "    \n",
    "    dense2 = tf.layers.dense(inputs = dense, units = 1024, activation = tf.nn.relu)\n",
    "    \n",
    "    # dropout\n",
    "    dropout =  tf.layers.dropout(inputs = dense2, rate = 0.2, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # receives [batch_size, 1024]\n",
    "    # returns [batch_size, 10]\n",
    "    output = tf.layers.dense(inputs = dropout, units = 120)\n",
    "    \n",
    "    predictions = tf.argmax(output, axis = 1)\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.PREDICT):\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = predictions)  \n",
    "    \n",
    "    losses = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = output)\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.TRAIN):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "        train = optimizer.minimize(losses, global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = losses, train_op = train)\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.EVAL):\n",
    "        eval_metrics_ops = {'accuracy': tf.metrics.accuracy(labels = labels, predictions = predictions)}\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = losses, eval_metric_ops = eval_metrics_ops) \n",
    "\n",
    "classifier = tf.estimator.Estimator(model_fn = create_network)\n",
    "\n",
    "train_function = tf.estimator.inputs.numpy_input_fn(x = {'x': train_images}, y = train_labels, \n",
    "                                                        batch_size= 1000, num_epochs= None, shuffle= True)\n",
    "classifier.train(input_fn = train_function, steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
